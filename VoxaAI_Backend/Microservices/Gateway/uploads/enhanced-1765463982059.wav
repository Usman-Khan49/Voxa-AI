{"error":"IndexTTS2 inference failed: TTS_ERROR: RuntimeError: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 11182080 bytes.\nTraceback (most recent call last):\n  File \"<string>\", line 18, in <module>\n  File \"C:\\Users\\Usman\\Desktop\\VoxaAi\\VoxaAI_Backend\\Microservices\\AI\\index-tts\\indextts\\infer_v2.py\", line 87, in __init__\n    load_checkpoint(self.gpt, self.gpt_path)\n  File \"C:\\Users\\Usman\\Desktop\\VoxaAi\\VoxaAI_Backend\\Microservices\\AI\\index-tts\\indextts\\utils\\checkpoint.py\", line 26, in load_checkpoint\n    checkpoint = torch.load(model_pth, map_location='cpu')\n  File \"C:\\Users\\Usman\\Desktop\\VoxaAi\\VoxaAI_Backend\\Microservices\\AI\\index-tts\\.venv\\lib\\site-packages\\torch\\serialization.py\", line 1521, in load\n    return _load(\n  File \"C:\\Users\\Usman\\Desktop\\VoxaAi\\VoxaAI_Backend\\Microservices\\AI\\index-tts\\.venv\\lib\\site-packages\\torch\\serialization.py\", line 2119, in _load\n    result = unpickler.load()\n  File \"C:\\Users\\Usman\\Desktop\\VoxaAi\\VoxaAI_Backend\\Microservices\\AI\\index-tts\\.venv\\lib\\site-packages\\torch\\_weights_only_unpickler.py\", line 532, in load\n    self.append(self.persistent_load(pid))\n  File \"C:\\Users\\Usman\\Desktop\\VoxaAi\\VoxaAI_Backend\\Microservices\\AI\\index-tts\\.venv\\lib\\site-packages\\torch\\serialization.py\", line 2083, in persistent_load\n    typed_storage = load_tensor(\n  File \"C:\\Users\\Usman\\Desktop\\VoxaAi\\VoxaAI_Backend\\Microservices\\AI\\index-tts\\.venv\\lib\\site-packages\\torch\\serialization.py\", line 2036, in load_tensor\n    zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)\nRuntimeError: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 11182080 bytes."}